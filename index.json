
    
    
    
    [{"authors":null,"categories":null,"content":"I am a Ph.D Student in Inria Lyon under the supervision of Rémi Gribonval and Elisa Riccietti, in the OCKHAM team led by Rémi Gribonval, working on the quantization and optimization of neural networks, studying their invariance by rescaling.\nMy Ph.D is financed by the project SHARP of the PEPR-IA.\nYou can find more details on my resume.\n","date":1740787200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1740787200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"2025-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Ph.D Student in Inria Lyon under the supervision of Rémi Gribonval and Elisa Riccietti, in the OCKHAM team led by Rémi Gribonval, working on the quantization and optimization of neural networks, studying their invariance by rescaling.","tags":null,"title":"Maël Chaumette","type":"authors"},{"authors":["Guillaume Lauga","Maël Chaumette","Edgar Desainte-Maréville","Étienne Lassalle","Arthur Lebeurrier"],"categories":null,"content":"","date":1740787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740787200,"objectID":"6787212e8cd571d8e419545c0617b8ea","permalink":"https://mael.chaumette.github.io/publication/multilevelgpt/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/publication/multilevelgpt/","section":"publication","summary":"In this article, we investigate the potential of multilevel approaches to accelerate the training of transformer architectures. Using an ordinary differential equation (ODE) interpretation of these architectures, we propose an appropriate way of varying the discretization of these ODE Transformers in order to accelerate the training. We validate our approach experimentally by a comparison with the standard training procedure.","tags":null,"title":"A multilevel approach to accelerate the training for Transformers","type":"publication"},{"authors":["Maël Chaumette","Rémi Gribonval","Élisa Riccietti"],"categories":null,"content":"","date":1740787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740787200,"objectID":"19ae9d50009df7f75529b917556e2305","permalink":"https://mael.chaumette.github.io/publication/croquant/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/publication/croquant/","section":"publication","summary":"This paper presents a quantization algorithm for complex-valued rank-one matrices, which exploits rescaling-invariances of the problem to obtain better results than round-to-nearest strategy. This algorithm can be used as a building block for an heuristic stategy to quantize complex-valued butterfly-structured sparse matrices appearing for example in the fast Fourier transform. Compared to element-wise round-to-nearest quantization we reduce by 30% the number of bits for a given precision on butterfly matrices, while maintaining a polynomial time complexity in the dimension of the matrices.","tags":null,"title":"CROQuant: Complex Rank-One Quantization Algorithm","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"dc228c085ddf4e4ac8697470bf2b36c1","permalink":"https://mael.chaumette.github.io/teaching/algo1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/teaching/algo1/","section":"teaching","summary":"","tags":null,"title":"Algorithms 1 L3","type":"teaching"}]